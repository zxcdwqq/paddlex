模型压缩
=======================================

PaddleX集成了PaddleSlim, 可帮助用户对模型进行裁剪和量化，减小模型的计算量和体积，提升模型的预测性能。

- 模型裁剪多适用于低性能设备，如CPU、移动端和端侧部署时使用，对于性能较好的GPU，裁剪不一定能带来性能的提升。
- 模型量化将模型的浮点型计算转为整型计算，从而加速模型的预测速度，减小模型的体积，对于PaddleLite在Arm设备上部署性能有明显提升。

.. toctree::
   :maxdepth: 1
   :caption: 文档目录:

   prune.md
   quant.md
